{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "161390c4",
   "metadata": {},
   "source": [
    "# Week 9: Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b0e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset...\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "if(\"dataset\" not in globals()):\n",
    "    root_dir = Path().resolve()\n",
    "    dataset = torchvision.datasets.MNIST(root_dir, download=True, transform=transforms.ToTensor())\n",
    "    train, test = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8), int(len(dataset) * 0.2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ae43b",
   "metadata": {},
   "source": [
    "First, load in MNIST and display a character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa75f49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print(\"Image Size:\", tuple(dataset[0][0].shape))\n",
    "plt.imshow(dataset[0][0].moveaxis(0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f2cc7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\") # GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # CPU\n",
    "    \n",
    "print(f\"Running PyTorch Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c513f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "to_device = lambda a: a.to(device)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size, shuffle=True)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82731cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for training a model...\n",
    "def train_model(\n",
    "    model, \n",
    "    train_data, \n",
    "    test_data, \n",
    "    optimizer, \n",
    "    error_func, \n",
    "    n_epochs,\n",
    "    device,\n",
    "    print_every=100,\n",
    "    print_accuracy=True\n",
    "):\n",
    "    for epoch_i in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        for i, (img, label) in enumerate(train_data, 1):\n",
    "            # Zero gradients...\n",
    "            model.zero_grad()\n",
    "            # Run model...\n",
    "            predicted = model.forward(img.to(device))\n",
    "            \n",
    "            # Compute loss, backpropigate, and optimize the weights...\n",
    "            loss = error_func(predicted, label.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if((i % print_every == 0) or (i == len(train_data))):\n",
    "                print(f\"Epoch: {epoch_i}/{n_epochs}, Iter: {i}/{len(train_data)}, Loss: {loss:.04f}\")\n",
    "                \n",
    "        # Run against the test set and train set at the end of each epoch to get accuracy...\n",
    "        if(print_accuracy):\n",
    "            model.eval()\n",
    "            acc1 = get_accuracy(model, train_data)\n",
    "            print(f\"Epoch {epoch_i} Train Accuracy: {acc1 * 100:.02f}%\")\n",
    "            acc2 = get_accuracy(model, test_data)\n",
    "            print(f\"Epoch {epoch_i} Test Accuracy: {acc2 * 100:.02f}%\\n\")\n",
    "    \n",
    "    return model\n",
    "        \n",
    "        \n",
    "def get_accuracy(model, data):\n",
    "        run = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for img, label in data:\n",
    "            run += len(img)\n",
    "            result = model.forward(img.to(device)).cpu().detach().numpy()\n",
    "            correct += np.sum(np.argmax(result, axis=1) == label.cpu().detach().numpy())\n",
    "        \n",
    "        return correct / run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85c690",
   "metadata": {},
   "source": [
    "### Model Without Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c67dbf",
   "metadata": {},
   "source": [
    "Our first model will be a regular MLP classifying MNIST digits without dropout. Recall that in this network, all neurons (or nodes) will be present for every training case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaNN(nn.Module):\n",
    "    def __init__(self, input_size: tuple, hidden_layer_sizes: list, class_count: int): \n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Linear(np.prod(input_size), hidden_layer_sizes[0]),\n",
    "            nn.LeakyReLU()\n",
    "        ]\n",
    "        \n",
    "        for this_size, next_size in zip(hidden_layer_sizes[:-1], hidden_layer_sizes[1:]):\n",
    "            layers.extend([\n",
    "                nn.Linear(this_size, next_size),\n",
    "                nn.LeakyReLU()\n",
    "            ])\n",
    "            \n",
    "        layers.append(nn.Linear(hidden_layer_sizes[-1], class_count))\n",
    "        \n",
    "        self._linear_layers = nn.Sequential(*layers)\n",
    "        self._softmax = nn.Softmax(-1)\n",
    "        \n",
    "    def linear_layer(self, index: int):\n",
    "        return self._linear_layers[index * 2]\n",
    "        \n",
    "    def forward(self, x: torch.tensor, exec_depth: int = None) -> torch.tensor:\n",
    "        if(exec_depth is None):\n",
    "            return self._softmax(self._linear_layers(x.reshape(x.shape[0], -1)))\n",
    "        else:\n",
    "            # Return internal values exec_layers layers in...\n",
    "            return self._linear_layers[:exec_depth * 2](x.reshape(x.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bba9cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: Below, set the number of hidden units per layer and number of output classes\n",
    "hidden_layers = [None] # this should be an array with units per hidden layer\n",
    "num_classes = None\n",
    "\n",
    "vnn = VanillaNN(dataset[0][0].shape, hidden_layers, num_classes).to(device)\n",
    "print(vnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0dfb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set epochs and learning rate. Be sure the network's performance has begun to plateau for a good comparison\n",
    "n_epochs = None\n",
    "lr = None\n",
    "\n",
    "# Set up everything...\n",
    "optimizer = optim.Adam(vnn.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ec9a3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vnn = train_model(vnn, train_loader, test_loader, optimizer, loss_func, n_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e65ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final Model Test Accuracy: {get_accuracy(vnn, test_loader) * 100:.02f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd30546",
   "metadata": {},
   "source": [
    "### Model With Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c492b3",
   "metadata": {},
   "source": [
    "Now, let's try the same network with dropout. Dropout is simple: For every layer, the input to any given neuron is zeroed out with probability *p*. When a neuron's input is zeroed out, it's effectively removed from the model. Which neurons are dropped are determined by a vector of 1's and 0's generated by a Bernoulli distribution (at least, in the paper) for each training case.\n",
    "\n",
    "Notably, dropout effectively turns a single model into an ensemble of models that share weights, where each model in the ensemble is a random subnetwork that only rarely gets trained.\n",
    "\n",
    "**TODO: How many subnetworks are possible in a network with *n* units?**\n",
    "\n",
    "**TODO: How does dropout change the relationship of units in the network with their neighbors?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcec0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size: tuple, \n",
    "        hidden_layer_sizes: list, \n",
    "        dropout_values: list, \n",
    "        class_count: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            #TODO: Add dropout here (hint: there's a PyTorch function for it).\n",
    "            #Which value from the dropout list should go here?\n",
    "            None,\n",
    "            nn.Linear(np.prod(input_size), hidden_layer_sizes[0]),\n",
    "            nn.LeakyReLU()\n",
    "        ]\n",
    "        \n",
    "        for this_size, next_size, dv in zip(hidden_layer_sizes[:-1], hidden_layer_sizes[1:], dropout_values[1:]):\n",
    "            layers.extend([\n",
    "                #TODO: Add dropout here too\n",
    "                None,\n",
    "                nn.Linear(this_size, next_size),\n",
    "                nn.LeakyReLU()\n",
    "            ])\n",
    "            \n",
    "        layers.extend([\n",
    "            #TODO: Last dropout call here. Which value should it take?\n",
    "            None,\n",
    "            nn.Linear(hidden_layer_sizes[-1], class_count)\n",
    "        ])\n",
    "        \n",
    "        self._linear_layers = nn.Sequential(*layers)\n",
    "        self._softmax = nn.Softmax(-1)\n",
    "        \n",
    "    def linear_layer(self, index: int):\n",
    "        return self._linear_layers[index * 3 + 1]\n",
    "        \n",
    "    def forward(self, x: torch.tensor, exec_depth: int = None) -> torch.tensor:\n",
    "        if(exec_depth is None):\n",
    "            return self._softmax(self._linear_layers(x.reshape(x.shape[0], -1)))\n",
    "        else:\n",
    "            # Return internal values exec_layers layers in...\n",
    "            return self._linear_layers[:exec_depth * 3](x.reshape(x.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Specify number of hidden units per layer, per-layer dropout probability (between 0 and 1), and number of \n",
    "# output classes. How many per-layer dropout probabilities does this model require?\n",
    "hidden_layers = [None]\n",
    "dropout_probs = [None]\n",
    "num_classes = None\n",
    "\n",
    "dnn = DropoutNN(dataset[0][0].shape, hidden_layers, dropout_probs, num_classes).to(device)\n",
    "print(dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e75f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set epochs and learning rate. Note that dropout substantially slows down training!\n",
    "n_epochs2 = None\n",
    "lr2 = None\n",
    "\n",
    "# Set up everything...\n",
    "optimizer2 = optim.Adam(dnn.parameters(), lr=lr2)\n",
    "loss_func2 = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc65722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dnn = train_model(dnn, train_loader, test_loader, optimizer2, loss_func2, n_epochs2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db67239",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.eval()\n",
    "print(f\"Final Model Test Accuracy: {get_accuracy(dnn, test_loader) * 100:.02f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2f6ad",
   "metadata": {},
   "source": [
    "In the interest of time: if the dropout model performs slightly worse than or equivalent to the vanilla model, there should still be clear differences in the layers visualized below. If you have the time, experiment with the number of epochs, learning rate, and dropout probabillities to maximize the dropout model's performance, then compare against the vanilla model.\n",
    "\n",
    "**TODO: How does the training rate of the dropout model compare to the vanilla model? Why does dropout have this effect on training rates?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4a09aa",
   "metadata": {},
   "source": [
    "### Visualizing Model Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ea24b",
   "metadata": {},
   "source": [
    "Now, let's visualize the first layer weights from both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ac228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_hidden_layer(\n",
    "    model: nn.Module, \n",
    "    title: str, \n",
    "    height: int, \n",
    "    width: int, \n",
    "    depth: int, \n",
    "    num_samples: int = 10\n",
    "):\n",
    "    # Get the weights...\n",
    "    weight = model.linear_layer(0).weight\n",
    "    # Detach them and reshape them into the image size...\n",
    "    weight = weight.cpu().detach().numpy().reshape(-1, depth, height, width)\n",
    "        \n",
    "    fig, axs = plt.subplots(depth, num_samples, squeeze=False)\n",
    "    fig.set_size_inches(3 * num_samples, 3 * depth)\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    selected_filters = np.random.choice(len(weight), num_samples, replace=False)\n",
    "    for i, sub_axs in zip(selected_filters, axs.T):\n",
    "        img = weight[i]\n",
    "        \n",
    "        for j, ax in enumerate(sub_axs):\n",
    "            ax.set_title(f\"Cell {i}, Channel {j}\")\n",
    "            ax.imshow(img[j])\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff7238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "d, h, w = dataset[0][0].shape\n",
    "plot_first_hidden_layer(vnn, \"VanillaNN First Layer Weights\", h, w, d)\n",
    "plot_first_hidden_layer(dnn, \"DropoutNN First Layer Weights\", h, w, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fea069e",
   "metadata": {},
   "source": [
    "Double click on each row of plots to make them larger!\n",
    "\n",
    "**TODO: Are there visual differences between the vanilla and dropout model weights? How does dropout cause these differences in the weights?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349794c",
   "metadata": {},
   "source": [
    "# Optimal Images "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badf38b1",
   "metadata": {},
   "source": [
    "Below, we choose random individual neurons from the 'vanilla' net and the dropout net. For each neuron, we train an optimal image to maximally activate its neuron, then display the optimal image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f471b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_optimal_image(\n",
    "    model: nn.Module,\n",
    "    run_through_layers: int,\n",
    "    nodes: int,\n",
    "    width: int,\n",
    "    height: int,\n",
    "    depth: int,\n",
    "    device,\n",
    "    learning_rate: int = 5e-4,\n",
    "    epochs: int = 4500,\n",
    "    optimize_range: bool = False\n",
    ") -> np.ndarray:\n",
    "    # Put model in evaluation mode, we only want to optimize the image...\n",
    "    model.eval()\n",
    "    # Create a random image...\n",
    "    img = torch.randn(1, depth, height, width, device=device, requires_grad=True)\n",
    "    optimizer = optim.Adam([img], lr=learning_rate)\n",
    "    loss_func = nn.MSELoss()\n",
    "    \n",
    "    print(f\"Optimize Values After Layer {model.linear_layer(run_through_layers - 1)}, Node: {nodes}\")\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        # Zero gradients...\n",
    "        if img.grad is not None:\n",
    "            img.grad.detach_()\n",
    "            img.grad.zero_()\n",
    "        model.zero_grad()\n",
    "        # Run model...\n",
    "        predicted = model.forward(img, run_through_layers)\n",
    "        \n",
    "        mask = np.zeros(predicted.shape[1], bool)\n",
    "        mask[nodes] = 1\n",
    "        \n",
    "        node_score = torch.min(predicted[0, mask])\n",
    "        not_node_score = torch.max(predicted[0, ~mask])\n",
    "        \n",
    "        # Compute loss, backpropigate, and optimize the weights...\n",
    "        # Our loss: Maximize the range between nodes of interest and other nodes\n",
    "        loss = -node_score if(not optimize_range) else -node_score + not_node_score\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # All images are made up of channels that range from 0 to 1, so clamp values within that range...\n",
    "        with torch.no_grad():\n",
    "            img.clamp_(0, 1)\n",
    "\n",
    "        if((i % 500 == 0) or (i == (epochs - 1))):\n",
    "            print(f\"Epoch: {i}/{epochs}, Loss: {loss:.02f}\")\n",
    "            \n",
    "    return img\n",
    "\n",
    "def random_optimal_images_from(\n",
    "    model: nn.Module, \n",
    "    layer: int, \n",
    "    num_samples: int,\n",
    "    width: int, \n",
    "    height: int, \n",
    "    depth: int, \n",
    "    device,\n",
    "    *args,\n",
    "    **kwargs\n",
    ") -> tuple:\n",
    "    imgs = []\n",
    "    samples = np.random.choice(model.linear_layer(layer - 1).weight.shape[0], num_samples, replace=False)\n",
    "    %matplotlib notebook\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        print(f\"Working on image {i + 1}/{num_samples}\")\n",
    "        imgs.append(\n",
    "            generate_optimal_image(model, layer, sample, height, width, depth, device, *args, **kwargs)\n",
    "        )\n",
    "    \n",
    "    fig, axs = plt.subplots(depth, num_samples, squeeze=False)\n",
    "    fig.set_size_inches(3 * num_samples, 3 * depth)\n",
    "    fig.suptitle(type(model).__name__)\n",
    "    \n",
    "    for img, sample_i, sub_axs in zip(imgs, samples, axs.T):\n",
    "        for j, ax in enumerate(sub_axs):\n",
    "            img2 = img.cpu().detach().numpy()[0, j]\n",
    "            ax.set_title(f\"Layer {layer}, Node {sample_i}, Channel {j}\")\n",
    "            m = ax.imshow(img2, cmap=\"plasma\") \n",
    "    \n",
    "    fig.colorbar(m)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "    return fig, axs, imgs, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510e636",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "vanilla_res = random_optimal_images_from(vnn, 4, 10, h, w, d, device, optimize_range=True)[0]\n",
    "dropout_res = random_optimal_images_from(dnn, 4, 10, h, w, d, device, optimize_range=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7cd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "vanilla_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34707278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dropout_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8a8aaf",
   "metadata": {},
   "source": [
    "**TODO: Are there any differences between the 'vanilla' net optimal images and the dropout net optimal images? If so, what do you think led to these differences?**\n",
    "\n",
    "**TODO: The above function allows you to randomly sample nodes from any layer of the network for generating optimal images (Currently set to layer 4, the final layer output). What results do you get when changing the layer optimal images are being generated for? How do the Vanilla NN and Dropout NN results compare and differ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470de886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
